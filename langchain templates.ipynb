{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53359078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81939573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23ba934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"text-davinci-003\", openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "982a8445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "template = \"\"\"\n",
    "I want to source {raw_material}. Where should I source from? Choose the country that has the lowest impact on CO2 emissions.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"raw_material\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "final_prompt = prompt.format(raw_material='Brassicas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d4aff47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Prompt: \n",
      "I want to source Brassicas. Where should I source from? Choose the country that has the lowest impact on CO2 emissions.\n",
      "\n",
      "-----------\n",
      "LLM Output: \n",
      "The best country to source Brassicas from in terms of lowest CO2 emissions is New Zealand. New Zealand has a relatively low emissions profile due to its use of renewable energy sources and its commitment to sustainable agriculture practices. Additionally, New Zealand has very strict regulations regarding food safety, making it an ideal choice for sourcing Brassicas.\n"
     ]
    }
   ],
   "source": [
    "print (f\"Final Prompt: {final_prompt}\")\n",
    "print (\"-----------\")\n",
    "print (f\"LLM Output: {llm(final_prompt)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
